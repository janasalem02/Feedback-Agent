# MongoDB integration for criteria and results storage
from pymongo import MongoClient
from core.config import settings, logger
from datetime import datetime
from typing import Dict, List, Optional
from dataclasses import dataclass
import sys
import os

@dataclass
class PointsAnalysisResult:
    """ูุชูุฌุฉ ุชุญููู ุงูููุงุท ุงูุฅูุฌุงุจูุฉ ูุงูุณูุจูุฉ"""
    analysis: dict
    error: str = None
    confidence: float = 0.0
    processing_time: float = 0.0
    total_points: int = 0
    positive_points: List[str] = None
    negative_points: List[str] = None
    
    def __post_init__(self):
        """ุชููุฆุฉ ุฅุถุงููุฉ ุจุนุฏ ุงูุฅูุดุงุก"""
        if self.positive_points is None:
            self.positive_points = []
        if self.negative_points is None:
            self.negative_points = []
        
        # ุงุณุชุฎุฑุงุฌ ุงูููุงุท ูู analysis ุฅุฐุง ูุงูุช ููุฌูุฏุฉ
        if isinstance(self.analysis, dict):
            if not self.positive_points and "positive_points" in self.analysis:
                self.positive_points = self.analysis.get("positive_points", [])
            if not self.negative_points and "negative_points" in self.analysis:
                self.negative_points = self.analysis.get("negative_points", [])
        
        # ุญุณุงุจ ุงูุนุฏุฏ ุงูุฅุฌูุงูู ุฅุฐุง ูู ูุชู ุชุญุฏูุฏู
        if self.total_points == 0:
            self.total_points = len(self.positive_points) + len(self.negative_points)

# Use a shared MongoDB connection and collection for all operations
mongo_url = getattr(settings, 'mongo_url', 'mongodb://localhost:27017/')
db_name = getattr(settings, 'database_name', 'audio_db')
criteria_collection_name = getattr(settings, 'criteria_collection', 'client')
results_collection_name = getattr(settings, 'collection_name', 'audio_files')
client = MongoClient(mongo_url)
db = client[db_name]
criteria_collection = db[criteria_collection_name]
results_collection = db[results_collection_name]

# โ ุฅุตูุงุญ ุดุงูู ููุดููุฉ ุงูุงุณุชูุฑุงุฏ
FeedbackPointsExtractor = None

# ุฏุงูุฉ ุงุณุชุฎุฑุงุฌ ุงูููุงุท ุงูุฅูุฌุงุจูุฉ ูุงูุณูุจูุฉ ูู ุงูุชุฑุงูุณูุฑูุจุช ุนุจุฑ LLaMA
def extract_points_with_llama(transcript: str) -> dict:
    """
    ุชุฑุณู ุงูุชุฑุงูุณูุฑูุจุช ุฅูู ูููุฐุฌ LLaMA 3.1 8B ูุชุณุชุฎุฑุฌ ุงูููุงุท ุงูุฅูุฌุงุจูุฉ ูุงูุณูุจูุฉ ุจุดูู ุฐูู
    ูุญุณูุฉ ููุณุฑุนุฉ ูุน timeout ุฃูู ูุจุฑููุจุช ูุฎุชุตุฑ
    """
    import requests
    import json
    
    try:
        # ูุญุงููุฉ ุงุณุชุฎุฏุงู Ollama ุฅุฐุง ูุงู ูุชุงุญ
        llama_url = "http://localhost:11434/api/generate"
        llama_model = "finalend/llama-3.1-storm:8b"
        
        prompt = f"""ุฃูุช ูุญูู ุฎุจูุฑ ูู ุงุณุชุฎุฑุงุฌ ุงูููุงุท ุงููููุฉ ูู ุงููุฑุงุฌุนุงุช. 

ูููุชู: ุงุณุชุฎุฑุฌ ุงูููุงุท ุงูุฅูุฌุงุจูุฉ ูุงูุณูุจูุฉ ุจุดูู ูุฎุชุตุฑ ูุจูุตุญู ูุงุถุญุฉ.

ููุงุนุฏ ุตุงุฑูุฉ:
- ูู ููุทุฉ ุฌููุฉ ูุงุญุฏุฉ ูุฎุชุตุฑุฉ ููุท
- ุงุณุชุฎุฏู ุงููุบุฉ ุงูุนุฑุจูุฉ ุงููุตุญู 
- ูุง ุชุถุน ูุฌุงููุงุช ุฃู ุนุจุงุฑุงุช ููุฐุจุฉ
- ุฑูุฒ ุนูู ุงูููุฑุฉ ุงูุฃุณุงุณูุฉ ููุท
- ูุง ุชูุฑุฑ ููุณ ุงููุนูู

ุฃูุซูุฉ:
ุฅูุฌุงุจู: "ุงูุทุนุงู ุดูู"ุ "ุงูุฎุฏูุฉ ุณุฑูุนุฉ"
ุณูุจู: "ุงูุฃุณุนุงุฑ ูุฑุชูุนุฉ"ุ "ุงูุชูุตูู ูุชุฃุฎุฑ"

ุงููุฑุงุฌุนุฉ: {transcript}

ุฃุฌุจ ุจุชูุณูู JSON ููุท:
{{
  "positive_points": ["ููุทุฉ ุฅูุฌุงุจูุฉ ูุฎุชุตุฑุฉ"],
  "negative_points": ["ููุทุฉ ุณูุจูุฉ ูุฎุชุตุฑุฉ"]
}}"""
        
        data = {
            "model": llama_model,
            "prompt": prompt,
            "stream": False,
            "options": {
                "temperature": 0.1,     # ุฃูู ุฌุฏุงู ููุฏูุฉ ูุงูุซุจุงุช
                "num_predict": 100,     # ุชูููู ุฃูุซุฑ ููุชุฑููุฒ
                "num_ctx": 512,         # context ุฃูู ููุชุฑููุฒ  
                "top_k": 3,            # ูุญุฏูุฏ ุฌุฏุงู ููุฏูุฉ
                "top_p": 0.5,          # ุฃูู ููุฏูุฉ
                "repeat_penalty": 1.2,  # ุชุฌูุจ ุงูุชูุฑุงุฑ ุฃูุซุฑ
                "stop": ["\n\n", "---", "ููุงุญุธุฉ:"]  # ุชููู ูุจูุฑ
            }
        }
        
        # timeout ุฃูุจุฑ ููุชุญููู ุงูููุตู - ุฒูุงุฏุฉ timeout
        response = requests.post(llama_url, json=data, timeout=30)
        response.raise_for_status()
        result = response.json()
        
        # ุงุณุชุฎุฑุงุฌ ุงููุชูุฌุฉ ูุชุญููููุง ูู JSON
        response_text = result.get("response", "").strip()
        logger.info(f"๐ค LLaMA Response: {response_text[:200]}...")
        
        # ูุญุงููุฉ ุงุณุชุฎุฑุงุฌ JSON ูู ุงููุชูุฌุฉ - ูุญุณูุฉ
        import re
        
        # ุงูุจุญุซ ุนู JSON ูู ุฃู ููุงู ูู ุงูุงุณุชุฌุงุจุฉ
        json_patterns = [
            r'\{[^}]*"positive_points"[^}]*"negative_points"[^}]*\}',  # ุฃููููุฉ ุนุงููุฉ
            r'\{.*?"positive_points".*?"negative_points".*?\}',        # ุนุงุฏู
            r'\{.*\}',                                                 # ุฃู JSON
        ]
        
        extracted_data = None
        for pattern in json_patterns:
            json_match = re.search(pattern, response_text, re.DOTALL)
            if json_match:
                try:
                    json_str = json_match.group()
                    extracted_data = json.loads(json_str)
                    logger.info(f"โ JSON extracted successfully with pattern: {pattern[:30]}...")
                    break
                except json.JSONDecodeError:
                    continue
        
        if extracted_data and "positive_points" in extracted_data and "negative_points" in extracted_data:
            
            # ุชูุธูู ุฅุถุงูู ููููุงุท ุงููุณุชุฎุฑุฌุฉ ูู LLaMA - ูุญุณู ูููุตุญู ูุงูุงุฎุชุตุงุฑ
            def clean_llama_points(points):
                """ุชูุธูู ุงูููุงุท ูุชููู ูุฎุชุตุฑุฉ ูุจูุตุญู ูุงุถุญุฉ"""
                cleaned = []
                
                # ุนุจุงุฑุงุช ุงููุฌุงููุฉ ูุงูููุงู ุงูุฒุงุฆุฏ
                courtesy_phrases = [
                    "ูุนุทููู ุงูุนุงููุฉ", "ูุนุทูู ุงูุนุงููุฉ", "ุชุณูููุง", "ูุดููุฑูู",
                    "ูุง ุดุงุก ุงููู", "ููุง ููู", "ุจุณ ููู", "ูุจุณ", "ูุนูู",
                    "ุจุตุฑุงุญุฉ", "ูุงููู", "ุฃููู ูู", "ูุด ุนุงุฑู", "ุดู ุจุฏู ุฃููู",
                    "ุงูุณูุงู ุนูููู", "ูุฑุญุจุง", "ุงููุง", "ููุง", "ููููู"
                ]
                
                # ูุฑุงุฏูุงุช ูููุตุญู ุงููุฎุชุตุฑุฉ
                formal_replacements = {
                    "ูุง ุนุฌุจูู": "ุบูุฑ ูุฑุถู",
                    "ูุง ุฃุญุจุจุชู": "ุบูุฑ ููุงุณุจ", 
                    "ุนุฌุจูู": "ููุงุณุจ",
                    "ุฃุญุจุจุชู": "ุฌูุฏ",
                    "ุชุนุงูููู ูุฑูุญ": "ุงูุฎุฏูุฉ ุฌูุฏุฉ",
                    "ูุง ุจุญุจู": "ุบูุฑ ููุถู",
                    "ุจุญุจู": "ููุถู",
                    "ูุชูุฑ ุญูู": "ููุชุงุฒ",
                    "ูุด ุญูู": "ุถุนูู",
                    "ูุฌุงูู": "ูุตู",
                    "ูุง ูุฌุงูู": "ูุง ูุตู"
                }
                
                for point in points:
                    if isinstance(point, str):
                        clean_point = point.strip()
                        
                        # ุฅุฒุงูุฉ ุงููุฌุงููุงุช
                        for phrase in courtesy_phrases:
                            clean_point = clean_point.replace(phrase, "").strip()
                        
                        # ุชุทุจูู ุงููุตุญู ุงููุฎุชุตุฑุฉ
                        for colloquial, formal in formal_replacements.items():
                            clean_point = clean_point.replace(colloquial, formal)
                        
                        # ุฅุฒุงูุฉ ุนูุงูุงุช ุงูุชุฑููู ุงูุฒุงุฆุฏุฉ
                        clean_point = clean_point.strip("ุ.ุ!ุ -\"'")
                        
                        # ุชุญููู ูุฌููุฉ ูุฎุชุตุฑุฉ ูุงุญุฏุฉ
                        if '.' in clean_point:
                            # ุฎุฐ ุฃูู ุฌููุฉ ููุท ุฅุฐุง ูุงู ููุงู ุนุฏุฉ ุฌูู
                            clean_point = clean_point.split('.')[0].strip()
                        
                        # ุงูุชุฃูุฏ ุฃู ุงูููุทุฉ ูููุฏุฉ ููุฎุชุตุฑุฉ (ุจูู 5-50 ุญุฑู)
                        if 5 <= len(clean_point) <= 50 and not clean_point.isdigit():
                            # ุฅุฒุงูุฉ ุงูููุงุท ุงูููุฑุฑุฉ ุฃู ุบูุฑ ุงููููุฏุฉ
                            if clean_point not in cleaned and len(clean_point.split()) <= 6:  # ุญุฏ ุฃูุตู 6 ูููุงุช
                                cleaned.append(clean_point)
                
                return cleaned[:4]  # ุญุฏ ุฃูุตู 4 ููุงุท ูุฎุชุตุฑุฉ ููู ููุน
            
            # ุชูุธูู ุงูููุงุท ุงูุฅูุฌุงุจูุฉ ูุงูุณูุจูุฉ
            if "positive_points" in extracted_data:
                extracted_data["positive_points"] = clean_llama_points(extracted_data["positive_points"])
            if "negative_points" in extracted_data:
                extracted_data["negative_points"] = clean_llama_points(extracted_data["negative_points"])
            
            logger.info("โ LLaMA analysis successful")
            return extracted_data
        else:
            # ูุนุงูุฌุฉ ูุญุณูุฉ ุฅุฐุง ูู ูุฑุฌุน JSON ุตุญูุญ
            logger.warning(f"โ๏ธ LLaMA returned invalid JSON format: {response_text[:100]}...")
            
            # ูุญุงููุฉ ุงุณุชุฎุฑุงุฌ ุงูููุงุท ูู ุงููุต ูุจุงุดุฑุฉ
            positive_matches = re.findall(r'(?:positive_points|ุฅูุฌุงุจู|ุงูุฅูุฌุงุจู).*?:.*?\[(.*?)\]', response_text, re.IGNORECASE | re.DOTALL)
            negative_matches = re.findall(r'(?:negative_points|ุณูุจู|ุงูุณูุจู).*?:.*?\[(.*?)\]', response_text, re.IGNORECASE | re.DOTALL)
            
            positive_points = []
            negative_points = []
            
            if positive_matches:
                for match in positive_matches[0].split(','):
                    clean_match = match.strip().strip('"\'')
                    if len(clean_match) > 3:
                        positive_points.append(clean_match)
            
            if negative_matches:
                for match in negative_matches[0].split(','):
                    clean_match = match.strip().strip('"\'')
                    if len(clean_match) > 3:
                        negative_points.append(clean_match)
            
            if positive_points or negative_points:
                logger.info("โ Extracted points from non-JSON response")
                return {
                    "positive_points": positive_points,
                    "negative_points": negative_points
                }
            else:
                # fallback ุฅุฐุง ูู ูุฑุฌุน ุดูุก ูููุฏ
                raise ValueError("Could not extract valid points from LLaMA response")
            
    except Exception as e:
        logger.warning(f"โ๏ธ LLaMA extraction failed: {e}, using enhanced fallback analysis")
        
        # ุชุญููู fallback ูุญุณู ุจูุงุก ุนูู ูููุงุช ููุชุงุญูุฉ ูุฃููุงุท ุฃูุซุฑ ุชูุฏูุงู
        positive_keywords = [
            "ููุชุงุฒ", "ุฑุงุฆุน", "ุฌูุฏ", "ูููุณ", "ุญูู", "ุณุฑูุน", "ุนูู ุงูููุช", 
            "ุฌูุฏุฉ ุนุงููุฉ", "ูุฐูุฐ", "ูุธูู", "ูุฑูุญ", "ุฃุนุฌุจูู", "ููุตุญ", "ููุงุณุจ",
            "ููู ุงูุชููุนุงุช", "ูุง ุดุงุก ุงููู", "ุจุงูููุนุฏ", "ูู ุงูููุช", "ูุฑุถู",
            "ุฒุงูู", "ุฑุงูู", "ูุณุนุฏูู", "ุนุงูู ุงุฎุฑ", "ุนุงูู ุขุฎุฑ", "ุชูุชุญ ุงูููุณ", 
            "ูุญุงูุธูู ุนูู ุงูุฌูุฏุฉ", "ุฎูุงุฑู ุงูุงูู", "ุฎูุงุฑู ุงูุฃูู", "ููุณ ุงูุทุนู", 
            "ููุณ ุงูุฌูุฏุฉ", "ุฑูุญู ุญููุฉ", "ุฑูุญุฉ ุญููุฉ", "ุทุนู ุญูู", "ุบูุฑู",
            "ููุณ ุงู", "ููุณ ุฃู", "ูุด ุงู", "ูุด ุฃู", "ุชุบุทู ุงูููุงู",
            "ุฑูุญู ุชุดุนุฑ", "ุฑูุญุฉ ุชุดุนุฑ", "ูุญุงูุธูู ุนูู", "ุฏุงุฆูุง ูุญุงูุธูู"
        ]
        
        negative_keywords = [
            "ุณูุก", "ุจุทูุก", "ุชุฃุฎูุฑ", "ูุด ูููุณ", "ุถุนูู", "ูุด ุญูู", "ูุชุฃุฎุฑ", 
            "ุบูุฑ ููุจูู", "ูุดููุฉ", "ุฎุทุฃ", "ูุดู", "ูุด ูุชููุน", "ูุง ูุณุชุงูู",
            "ูุด ุฑุงุถู", "ูุญุจุท", "ุฒุนูุงู", "ุบุงูู", "ูุฑุชูุน", "ุจุงูุธ", "ุฑุฏูุก",
            "ูู ูุนุฌุจูู", "ูุง ุนุฌุจูู", "ุบูุฑ ุฑุงุถู", "ุชุญุช ุงูุชููุนุงุช", "ุฃุจุฏุง ูุง ุนุฌุจูู",
            "ุจูุงุก", "ูุด ุนุงุฌุจูู", "ูุง ุจุญุจู", "ููุฑู", "ูุณุฎ"
        ]
        
        # ุฃููุงุท ุณูุจูุฉ ุฃูุซุฑ ุชุนููุฏุงู - ุฎุงุตุฉ ููููู
        negative_patterns = [
            r"ุฃุจุฏุง\s+ูุง\s+ุนุฌุจ",          # "ุฃุจุฏุง ูุง ุนุฌุจูู" - CRITICAL
            r"ูู\s+ููู\s+\w*", r"ูู\s+ุชูู\s+\w*", r"ูุง\s+ูุงู\s+\w*", 
            r"ูุด\s+\w+", r"ุบูุฑ\s+\w+", r"ุจุฏูู\s+\w+", r"ูุง\s+ูู\s+\w*",
            r"ูู\s+ูุนุฌุจ", r"ูุง\s+ุนุฌุจ", r"ูุด\s+ุนุงุฌุจ"
        ]
        
        # ุฃููุงุท ุฅูุฌุงุจูุฉ ุฎุงุตุฉ ููุนุจุงุฑุงุช ุงููุนูุฏุฉ
        positive_patterns = [
            r"ููุณ\s+ุฃู\s+ููู", r"ููุณ\s+ุงู\s+ููู",  # "ููุณ ุฃู ูููุฉ" = ูุฏูุญ
            r"ูุด\s+ุฃู\s+ููู", r"ูุด\s+ุงู\s+ููู",    # "ูุด ุฃู ูููุฉ" = ูุฏูุญ
            r"ุนุงูู\s+ุขุฎุฑ", r"ุนุงูู\s+ุงุฎุฑ",           # "ุนุงูู ุขุฎุฑ" = ุฅูุฌุงุจู ููู
            r"ุชูุชุญ\s+ุงูููุณ", r"ุชุบุทู\s+ุงูููุงู",      # ุนุจุงุฑุงุช ุฅูุฌุงุจูุฉ ูููุฉ
            r"ูุญุงูุธูู\s+ุนูู", r"ุฏุงุฆูุง\s+ูุญุงูุธูู"    # ุงูุญูุงุธ ุนูู ุงูุฌูุฏุฉ
        ]
        
        transcript_lower = transcript.lower()
        positive_points = []
        negative_points = []
        
        # ุชูุณูู ุงููุต ูุฌูู ุฃูุซุฑ ุฐูุงุกู ูุชูุตููุงู
        import re
        
        # ุชูุณูู ุจูุงุกู ุนูู ุนูุงูุงุช ุงูุชุฑููู ูุงููููุงุช ุงูุงูุชูุงููุฉ
        sentences = re.split(r'[.!?ุุ]', transcript)
        
        # ุชูุณูู ุฅุถุงูู ุจูุงุกู ุนูู ูููุงุช ุงูุฑุจุท
        extended_sentences = []
        for sentence in sentences:
            # ุชูุณูู ุจูุงุกู ุนูู ูููุงุช ูุซู "ููู"ุ "ุจุณ"ุ "ู"ุ "ุฃูุง"
            parts = re.split(r'\s+(ููู|ุจุณ|ูููู|ุฃูุง|ูุงููุดููุฉ|ูุงูุนูุจ|ูุงูุญุงุฌุฉ ุงููุญูุฏุฉ|ุจุงููุณุจุฉ)\s+', sentence)
            for part in parts:
                if part.strip() and len(part.strip()) > 10:  # ุชุฌุงูู ุงููููุงุช ุงููุตูุฑุฉ
                    extended_sentences.append(part.strip())
        
        # ุชุฌููุน ุงูุฌูู ุงูููุงุฆู
        final_sentences = []
        for sentence in extended_sentences:
            sentence = sentence.strip()
            if len(sentence) > 10:  # ุทูู ุฃุฏูู ููุฌููุฉ
                final_sentences.append(sentence)
        
        logger.info(f"๐ Split text into {len(final_sentences)} sentences for analysis")
        
        for sentence in final_sentences:
            sentence_lower = sentence.lower()
            
            # ูุญุต ุงูุฃููุงุท ุงูุฅูุฌุงุจูุฉ ุงููุนูุฏุฉ ุฃููุงู (ุฃููููุฉ ุนุงููุฉ)
            has_positive_pattern = any(re.search(pattern, sentence_lower) for pattern in positive_patterns)
            
            # ูุญุต ุงูุฃููุงุท ุงูุณูุจูุฉ ุงููุนูุฏุฉ (ุฃููููุฉ ุนุงููุฉ)
            has_negative_pattern = any(re.search(pattern, sentence_lower) for pattern in negative_patterns)
            
            # ูุญุต ุงููููุงุช ุงูููุชุงุญูุฉ
            positive_score = sum(1 for word in positive_keywords if word in sentence_lower)
            negative_score = sum(1 for word in negative_keywords if word in sentence_lower)
            
            # ุฅุถุงูุฉ ููุงุท ุฅุถุงููุฉ ููุฃููุงุท ุงูุฅูุฌุงุจูุฉ ุงููุนูุฏุฉ
            if has_positive_pattern:
                positive_score += 5  # ูุฒู ุนุงูู ุฌุฏุงู ููุฃููุงุท ุงูุฅูุฌุงุจูุฉ
                logger.info(f"๐ข STRONG POSITIVE pattern detected: {sentence[:50]}...")
            
            # ุฅุถุงูุฉ ููุงุท ุฅุถุงููุฉ ููุฃููุงุท ุงูุณูุจูุฉ
            if has_negative_pattern:
                negative_score += 3  # ุฒูุงุฏุฉ ุงููุฒู ููุฃููุงุท ุงูุณูุจูุฉ
                logger.info(f"๐ด Negative pattern detected: {sentence[:50]}...")
            
            # ุฎุงุต: ูุญุต ููุท "ุฃุจุฏุง ูุง ุนุฌุจูู" ูุจุงุดุฑุฉ
            if "ุฃุจุฏุง ูุง ุนุฌุจ" in sentence_lower:
                negative_score += 5  # ูุฒู ุนุงูู ุฌุฏุงู
                logger.info(f"๐จ CRITICAL NEGATIVE: 'ุฃุจุฏุง ูุง ุนุฌุจ' detected")
            
            # ูุญุต ุฅุถุงูู ูููููุงุช ุงูุฅูุฌุงุจูุฉ ุงููููุฉ
            strong_positive_words = ["ููุชุงุฒ", "ุฑุงุฆุน", "ุฌูุฏ ุฌุฏุงู", "ุฃุนุฌุจูู", "ุญุจูุชู", "ุฒุงูู", "ุฑุงูู"]
            if any(word in sentence_lower for word in strong_positive_words):
                positive_score += 2
                logger.info(f"๐ข Strong positive detected: {sentence[:50]}...")
            
            # ุฏุงูุฉ ุชุญุณูู ุงูููุทุฉ ูููุตุญู ุงููุฎุชุตุฑุฉ
            def clean_and_formalize_point(text):
                """ุชูุธูู ูุชุญููู ุงูููุทุฉ ููุตุญู ูุฎุชุตุฑุฉ"""
                text = text.strip()
                
                # ุฅุฒุงูุฉ ุงููููุงุช ุงูุฒุงุฆุฏุฉ ุฃููุงู
                filler_words = [
                    "ุจุตุฑุงุญุฉ", "ูุงููู", "ูุนูู", "ุฃููู ูู", "ูุด ุนุงุฑู", 
                    "ูุนุทููู ุงูุนุงููุฉ", "ุชุณูููุง", "ูุง ุดุงุก ุงููู", "ููุง ููู", "ุจุณ ููู"
                ]
                
                for word in filler_words:
                    text = text.replace(word, "").strip()
                
                # ุชุญููู ูููุตุญู ุงููุฎุชุตุฑุฉ
                formal_conversions = {
                    # ุชุญููู ุงูุนุงููุฉ ูููุตุญู
                    "ุนุฌุจูู": "ุฃุนุฌุจูู",
                    "ูุง ุนุฌุจูู": "ูู ูุนุฌุจูู", 
                    "ุฃุจุฏุง ูุง ุนุฌุจูู": "ูู ูุนุฌุจูู ุฅุทูุงูุงู",
                    "ูุชูุฑ ุญูู": "ููุชุงุฒ",
                    "ูุด ุญูู": "ุถุนูู",
                    "ุฒุงูู": "ูุฐูุฐ",
                    "ุฑุงูู": "ููุนุด",
                    "ูููุณ": "ุฌูุฏ",
                    "ูุฑูุญ": "ููุงุณุจ",
                    "ูุฌุงูู": "ูุตู",
                    "ูุง ูุฌุงูู": "ูุง ูุตู",
                    "ุจุงูููุนุฏ": "ูู ุงูููุนุฏ",
                    "ูุชุฃุฎุฑ": "ูุชุฃุฎุฑ",
                    "ุบุงูู": "ูููู",
                    
                    # ุชุนุจูุฑุงุช ูุฑูุจุฉ
                    "ุชุนุงูููู ูุฑูุญ": "ุงูุชุนุงูู ููุงุณุจ",
                    "ุฎุฏูุฉ ุงูุนููุงุก": "ุงูุฎุฏูุฉ",
                    "ุจูู ุงูุนููุฏ": "ุงูููุชุฌ",
                    "ุงูุทุนู": "ุงูุทุนู",
                    "ุงูุฑูุญุฉ": "ุงูุฑุงุฆุญุฉ"
                }
                
                # ุชุทุจูู ุงูุชุญูููุงุช
                for colloquial, formal in formal_conversions.items():
                    text = text.replace(colloquial, formal)
                
                # ุงุฎุชุตุงุฑ ููููุงุท ุงูุทูููุฉ - ุงุณุชุฎุฑุงุฌ ุงูููุฑุฉ ุงูุฃุณุงุณูุฉ
                if len(text) > 40:
                    # ุงูุจุญุซ ุนู ุงููููุฉ ุงูููุชุงุญูุฉ ุงูุฃุณุงุณูุฉ
                    key_concepts = {
                        "ูุฐูุฐ": "ุงูุทุนู ูุฐูุฐ",
                        "ููุชุงุฒ": "ููุชุงุฒ", 
                        "ุฌูุฏ": "ุฌูุฏ",
                        "ุถุนูู": "ุถุนูู",
                        "ุณุฑูุน": "ุณุฑูุน",
                        "ูุชุฃุฎุฑ": "ูุชุฃุฎุฑ",
                        "ูููู": "ูููู",
                        "ููุนุด": "ููุนุด",
                        "ููุงุณุจ": "ููุงุณุจ",
                        "ุงูุฎุฏูุฉ": "ุงูุฎุฏูุฉ ุฌูุฏุฉ",
                        "ุงูููุนุฏ": "ูู ุงูููุนุฏ"
                    }
                    
                    for concept, summary in key_concepts.items():
                        if concept in text:
                            return summary
                
                # ุชูุธูู ููุงุฆู
                text = ' '.join(text.split())  # ุฅุฒุงูุฉ ุงููุณุงูุงุช ุงูุฒุงุฆุฏุฉ
                text = text.strip("ุ.ุ!ุ -\"'")
                
                # ุงูุชุฃูุฏ ูู ุงูุทูู ุงูููุงุณุจ (5-30 ุญุฑู ููุงุฎุชุตุงุฑ)
                if 5 <= len(text) <= 30:
                    return text
                elif len(text) > 30:
                    # ูุทุน ุนูุฏ ุฃูู 30 ุญุฑู ูุน ุงูุญูุงุธ ุนูู ุณูุงูุฉ ุงููููุฉ
                    words = text.split()
                    short_text = ""
                    for word in words:
                        if len(short_text + " " + word) <= 30:
                            short_text += " " + word if short_text else word
                        else:
                            break
                    return short_text.strip()
                
                return text if len(text) >= 5 else None
            
            # ุงุชุฎุงุฐ ุงููุฑุงุฑ ุจูุงุกู ุนูู ุงูููุงุท ูุน ุฃููููุฉ ููุฃููุงุท ุงููุนูุฏุฉ
            if has_positive_pattern or (positive_score > negative_score and positive_score > 0):
                clean_sentence = clean_and_formalize_point(sentence)
                if clean_sentence and len(clean_sentence) > 3:
                    positive_points.append(clean_sentence)
                    logger.info(f"โก๏ธ Added to POSITIVE: {clean_sentence}")
            elif has_negative_pattern or (negative_score > positive_score and (negative_score > 0 or has_negative_pattern)):
                clean_sentence = clean_and_formalize_point(sentence)
                if clean_sentence and len(clean_sentence) > 3:
                    negative_points.append(clean_sentence)
                    logger.info(f"โก๏ธ Added to NEGATIVE: {clean_sentence}")
            elif positive_score == negative_score and positive_score > 0:
                # ูู ุญุงูุฉ ุงูุชุนุงุฏูุ ุงุณุชุฎุฏู ุงูุณูุงู ูุน ุชูุถูู ุงูุฅูุฌุงุจู
                clean_sentence = clean_and_formalize_point(sentence)
                if clean_sentence and len(clean_sentence) > 3:
                    if any(neg_word in sentence_lower for neg_word in ["ูุด", "ูู", "ูุง", "ุบูุฑ"]) and not has_positive_pattern:
                        negative_points.append(clean_sentence)
                        logger.info(f"โก๏ธ TIED->NEGATIVE (context): {clean_sentence}")
                    else:
                        positive_points.append(clean_sentence)
                        logger.info(f"โก๏ธ TIED->POSITIVE (context): {clean_sentence}")
        
        # ุฅุถุงูุฉ ููุงุท ุงูุชุฑุงุถูุฉ ุฅุฐุง ูู ูุฌุฏ ุดูุก ุฃู ุฅุฐุง ูุงูุช ุงูููุงุท ููููุฉ
        if not positive_points and not negative_points:
            positive_points = ["ุชู ุงุณุชูุงู ุงูุชุนููู"]
        elif len(negative_points) == 0 and len(positive_points) > 0:
            # ูุญุงููุฉ ุงูุจุญุซ ุนู ููุงุท ุณูุจูุฉ ูุฎููุฉ
            hidden_negatives = []
            for sentence in sentences:
                if any(word in sentence.lower() for word in ["ููู", "ุจุณ", "ุฅูุง", "ูุง ุนุฏุง", "ุบูุฑ"]):
                    hidden_negatives.append(sentence.strip())
            if hidden_negatives:
                negative_points = hidden_negatives[:2]
        
        # ุชูุธูู ููุงุฆู ููููุงุท - ุชุทุจูู ุงููุตุญู ุงููุฎุชุตุฑุฉ
        def final_clean_points(points):
            """ุชูุธูู ููุงุฆู ููููุงุท ูุน ุงูุชุฑููุฒ ุนูู ุงููุตุญู ุงููุฎุชุตุฑุฉ"""
            cleaned = []
            seen = set()
            
            for point in points:
                # ุชุทุจูู ุงูุชูุธูู ูุงูุชุญููู ูููุตุญู
                clean = clean_and_formalize_point(point)
                if not clean:
                    continue
                    
                # ุงูุชุฃูุฏ ูู ุนุฏู ุงูุชูุฑุงุฑ ูุงูุทูู ุงูููุงุณุจ ููุงุฎุชุตุงุฑ
                clean_lower = clean.lower()
                if (clean_lower not in seen and 
                    5 <= len(clean) <= 35 and  # ุญุฏ ุฃูุตู 35 ุญุฑู ููุงุฎุชุตุงุฑ
                    len(clean.split()) <= 6):   # ุญุฏ ุฃูุตู 6 ูููุงุช
                    seen.add(clean_lower)
                    cleaned.append(clean)
            
            return cleaned[:3]  # ุญุฏ ุฃูุตู 3 ููุงุท ูุฎุชุตุฑุฉ ููุท
        
        positive_points = final_clean_points(positive_points)
        negative_points = final_clean_points(negative_points)
        
        return {
            "positive_points": positive_points,
            "negative_points": negative_points
        }

# ุฏุงูุฉ ุชุตููู ุงูููุทุฉ ูุฑุจุทูุง ุจุงููุฑุงูุชูุฑูุง ุนุจุฑ LLaMA
import requests
def classify_point_with_llama(point: str, criteria_list: list) -> dict:
    """
    ุชุฑุณู ุงูููุทุฉ ููุงุฆูุฉ ุงููุฑุงูุชูุฑูุง ุฅูู ููุฏูู LLaMA ุนุจุฑ API ููุฎุชุงุฑ ุงูุฃูุณุจ ุฏูุงููุงู.
    ูุญุณูุฉ ููุณุฑุนุฉ ูุน ุจุฑููุจุช ูุฎุชุตุฑ ูtimeout ุฃูู
    """
    try:
        llama_url = "http://localhost:11434/api/generate"
        llama_model = "finalend/llama-3.1-storm:8b"
        
        # ุจูุงุก ุงูุจุฑููุจุช ูุฎุชุตุฑ ููุณุฑุนุฉ
        criteria_names = [c['name'] for c in criteria_list[:5]]  # ุญุฏ ุฃูุตู 5 ูุนุงููุฑ ููุณุฑุนุฉ
        prompt = f"""ุงูููุทุฉ: {point[:100]}
ุงููุนุงููุฑ: {', '.join(criteria_names)}
ุงุฎุชุฑ ุงูุฃูุณุจ ููุท:"""
        
        data = {
            "model": llama_model,
            "prompt": prompt,
            "stream": False,
            "options": {
                "temperature": 0.2,    # ุฃูู ููุณุฑุนุฉ 
                "num_predict": 20,     # ุฃูู tokens
                "num_ctx": 256,        # context ุฃุตุบุฑ
                "top_k": 5,           # ุฃุณุฑุน
                "top_p": 0.7
            }
        }
        
        # timeout ุฃูู ููุณุฑุนุฉ
        response = requests.post(llama_url, json=data, timeout=10)
        response.raise_for_status()
        result = response.json()
        criteria_name = result.get("response", "").strip()
        
        # ุงุจุญุซ ุนู ุงููุฑุงูุชูุฑูุง ุงููุทุงุจูุฉ ููุงุณู ุงููุณุชุฑุฌุน
        for c in criteria_list:
            if criteria_name and criteria_name.lower() in c["name"].lower():
                logger.info(f"โ LLaMA matched criteria: {criteria_name}")
                return {
                    "criteria_id": c.get("id"),
                    "criteria_name": c.get("name"),
                    "criteria_weight": c.get("weight", 0.0)
                }
        
        # ุฅุฐุง ูู ูุฌุฏ ูุทุงุจูุฉ ุฏูููุฉุ ุงุจุญุซ ุนู ุฃูุฑุจ ูุทุงุจูุฉ
        for c in criteria_list:
            if any(word.lower() in c["name"].lower() for word in criteria_name.split() if word):
                logger.info(f"โ LLaMA partial match: {c['name']}")
                return {
                    "criteria_id": c.get("id"),
                    "criteria_name": c.get("name"),
                    "criteria_weight": c.get("weight", 0.0)
                }
                
    except Exception as e:
        logger.warning(f"โ๏ธ LLaMA classification failed: {e}, using fallback")
    
    # Fallback: ุฃูุฑุจ ูุฑุงูุชูุฑูุง ุฏูุงููุงู
    import difflib
    best_match = None
    best_score = 0.0
    
    point_lower = point.lower()
    
    for c in criteria_list:
        criteria_name_lower = c["name"].lower()
        
        # ุญุณุงุจ ุงูุชุดุงุจู
        score = difflib.SequenceMatcher(None, point_lower, criteria_name_lower).ratio()
        
        # ุจููุต ูููููุงุช ุงููุดุชุฑูุฉ
        point_words = set(point_lower.split())
        criteria_words = set(criteria_name_lower.split())
        common_words = point_words.intersection(criteria_words)
        if common_words:
            score += len(common_words) * 0.2
        
        # ุจููุต ููุชุถููู
        if criteria_name_lower in point_lower or any(word in criteria_name_lower for word in point_words):
            score += 0.3
        
        if score > best_score:
            best_score = score
            best_match = c
    
    # ุฅุฐุง ูุฌุฏ ุฃู ุชุทุงุจู ูุนููู (>0.1)ุ ุฃุนุฏ ุงููุฑุงูุชูุฑูุง ุงูุฃูุฑุจ
    if best_match and best_score > 0.1:
        logger.info(f"โ Fallback match: {best_match['name']} (score: {best_score:.2f})")
        return {
            "criteria_id": best_match.get("id"),
            "criteria_name": best_match.get("name"),
            "criteria_weight": best_match.get("weight", 0.0)
        }
    
    # ุฅุฐุง ูู ููุฌุฏ ุฃู ุชุทุงุจู ูุนูููุ ุฃุนุฏ None
    logger.warning(f"โ๏ธ No suitable criteria found for: {point}")
    return {
        "criteria_id": None,
        "criteria_name": None,
        "criteria_weight": 0.0
    }

def import_feedback_extractor():
    """ุฏุงูุฉ ูุงุณุชูุฑุงุฏ FeedbackPointsExtractor ูุน ูุนุงูุฌุฉ ุดุงููุฉ ููุฃุฎุทุงุก"""
    global FeedbackPointsExtractor
    
    # ุฅุถุงูุฉ ุงููุฌูุฏ ุงูุฌุฐุฑ ูููุณุงุฑ ุฅุฐุง ูู ููู ููุฌูุฏุงู
    current_dir = os.path.dirname(os.path.abspath(__file__))
    if current_dir not in sys.path:
        sys.path.insert(0, current_dir)
    
    # ูุงุฆูุฉ ุงููุณุงุฑุงุช ุงููุฎุชููุฉ ููุชุฌุฑุจุฉ
    import_paths = [
        "services.feedback_points_extractor",
        "feedback_points_extractor",
        "services/feedback_points_extractor",
        "core.feedback_points_extractor"
    ]
    
    for import_path in import_paths:
        try:
            if "." in import_path:
                # ุงุณุชูุฑุงุฏ module
                module_parts = import_path.split(".")
                module_name = module_parts[-1]
                module_path = ".".join(module_parts[:-1])
                
                if module_path:
                    from importlib import import_module
                    module = import_module(import_path)
                    FeedbackPointsExtractor = getattr(module, 'FeedbackPointsExtractor')
                else:
                    exec(f"from {import_path} import FeedbackPointsExtractor")
            else:
                # ุงุณุชูุฑุงุฏ ูุจุงุดุฑ
                exec(f"from {import_path} import FeedbackPointsExtractor")
            
            logger.info(f"โ Successfully imported FeedbackPointsExtractor from: {import_path}")
            return True
            
        except ImportError as e:
            logger.debug(f"โ Failed to import from {import_path}: {e}")
            continue
        except Exception as e:
            logger.debug(f"โ Unexpected error importing from {import_path}: {e}")
            continue
    
    # ุฅุฐุง ูุดู ุฌููุน ุงููุญุงููุงุชุ ุฅูุดุงุก class ุจุฏูู
    logger.warning("โ Could not import FeedbackPointsExtractor from any path")
    create_fallback_extractor()
    return False

def create_fallback_extractor():
    """ุฅูุดุงุก class ุจุฏูู ูู ุญุงูุฉ ูุดู ุงูุงุณุชูุฑุงุฏ"""
    global FeedbackPointsExtractor
    
    class FallbackFeedbackPointsExtractor:
        """Class ุจุฏูู ูุคูุช ูู ุญุงูุฉ ุนุฏู ุชููุฑ ุงููุณุชุฎุฑุฌ ุงูุฃุตูู"""
        
        def _init_(self):
            self.model_name = "fallback_model"
            self.is_connected = False
            logger.warning("โ Using fallback FeedbackPointsExtractor - original not found")
            logger.info("๐ก To fix this:")
            logger.info("   1. Ensure feedback_points_extractor.py exists")
            logger.info("   2. Create services/ folder and move the file there")
            logger.info("   3. Add _init_.py to services/ folder")
        
        def analyze_transcript(self, data):
            """ุชุญููู ุจุฏูู ุนุจุฑ ุงูุจุฑููุจุช ุจุงุณุชุฎุฏุงู extract_points_with_llama"""
            logger.warning("โ Using fallback extraction - please fix import path")

            # ุงุณุชุฎุฏู ุฏุงูุฉ ุงูุชุญููู ุงูุฐูู ุญุชู ูู ูุถุน fallback
            if isinstance(data, dict) and "transcript" in data:
                transcript = data["transcript"]
                if isinstance(transcript, str) and len(transcript.strip()) > 0:
                    try:
                        result = extract_points_with_llama(transcript)
                        positive_points = result.get("positive_points", [])
                        negative_points = result.get("negative_points", [])
                        return PointsAnalysisResult(
                            analysis={
                                "positive_points": positive_points,
                                "negative_points": negative_points
                            },
                            error=None,
                            confidence=0.5,
                            processing_time=0.2,
                            total_points=len(positive_points) + len(negative_points),
                            positive_points=positive_points,
                            negative_points=negative_points
                        )
                    except Exception as e:
                        logger.error(f"โ Fallback extraction failed: {e}")
                        return PointsAnalysisResult(
                            analysis={"positive_points": [], "negative_points": []},
                            error=str(e),
                            confidence=0.0,
                            processing_time=0.0,
                            total_points=0,
                            positive_points=[],
                            negative_points=[]
                        )

            return PointsAnalysisResult(
                analysis={"positive_points": [], "negative_points": []},
                error="FeedbackPointsExtractor not available - using fallback with prompt",
                confidence=0.0,
                processing_time=0.0,
                total_points=0,
                positive_points=[],
                negative_points=[]
            )
    
    FeedbackPointsExtractor = FallbackFeedbackPointsExtractor
    logger.info("โ Fallback FeedbackPointsExtractor created successfully")

# ุชูููุฐ ุงูุงุณุชูุฑุงุฏ ุนูุฏ ุชุญููู ุงููุญุฏุฉ
import_success = import_feedback_extractor()

def analyze_and_calculate_scores(transcript: str, client_id: str) -> dict:
    """
    1. Fetch product criteria from MongoDB using client_id
    2. Analyze transcript with LLaMA (extract points)
    3. Map points to criteria
    4. Calculate percentage scores
    5. Return analysis object with all details
    """
    try:
        logger.info(f"๐ Starting analysis for client_id: {client_id}")
        
        # ุงูุชุญูู ูู ุชููุฑ ุงููุณุชุฎุฑุฌ
        if FeedbackPointsExtractor is None:
            logger.error("โ FeedbackPointsExtractor not available")
            return {"error": "FeedbackPointsExtractor not available"}
        
        # 1. Fetch criteria by _id (always use ObjectId)
        from bson import ObjectId
        criteria_doc = None
        try:
            criteria_doc = criteria_collection.find_one({"_id": ObjectId(client_id)})
        except Exception:
            criteria_doc = None
        if not criteria_doc or "criteria" not in criteria_doc:
            logger.error(f"โ No criteria found for client id: {client_id}")
            return {"error": "No criteria found for this client id"}
        criteria_list = criteria_doc["criteria"]
        logger.info(f"๐ Found {len(criteria_list)} criteria for client id '{client_id}'")
        
        # Build a mapping for fast lookup
        criteria_map = {}
        for c in criteria_list:
            name = c.get("name", "")
            if not isinstance(name, str):
                logger.warning(f"โ Skipping criteria with non-string name: {name} (type: {type(name)})")
                continue
            key = name.strip()
            criteria_map[key] = {"id": c.get("id"), "weight": c.get("weight", 0.0)}
        
        # 2. Analyze transcript with LLaMA (extract points and link to criteria)
        logger.info("๐ Extracting feedback points and linking to criteria via LLaMA...")
        extractor = FeedbackPointsExtractor()
        
        # โ ุฅุตูุงุญ ุงููุดููุฉ: ูุนุงูุฌุฉ ุฃูุถู ูููุฏุฎูุงุช
        if isinstance(transcript, dict):
            transcript_text = transcript.get("text", "")
        else:
            transcript_text = str(transcript) if transcript else ""
        
        # ุชุญุถูุฑ ุงูุจูุงูุงุช ูููุณุชุฎุฑุฌ
        llama_input = {
            "transcript": transcript_text,
            "criteria": criteria_list
        }
        
        points_result = extractor.analyze_transcript(llama_input)

        if hasattr(points_result, 'error') and points_result.error:
            logger.error(f"โ Points extraction failed: {points_result.error}")
            return {"error": f"Points extraction failed: {points_result.error}"}

        # โ ุฅุตูุงุญ ูุนุงูุฌุฉ ุงููุชุงุฆุฌ ูุน ุงูุชุญูู ูู ุงูุฃููุงุน
        analysis_data = getattr(points_result, 'analysis', {}) if hasattr(points_result, 'analysis') else {}
        raw_positive_points = analysis_data.get("positive_points", [])
        raw_negative_points = analysis_data.get("negative_points", [])

        # ุฏุงูุฉ ุชุตููู ุฐูู ููููุทุฉ ุนุจุฑ LLaMA
        def classify_point_with_llama(point_text, criteria_list):
            """
            ุชุฑุณู ุงูููุทุฉ ููุงุฆูุฉ ุงููุนุงููุฑ ุฅูู ูููุฐุฌ ูุบูู ููุญุฏุฏ ุงููุนูุงุฑ ุงูุฃูุณุจ ุฏูุงููุงู
            ูููู ุชุนุฏูู ุงูุจุฑููุจุช ุญุณุจ ุงููููุฐุฌ ุงููุณุชุฎุฏู
            """
            # ูุซุงู ุจุฑููุจุช ุจุณูุท (ููุชุฑุถ ูุฌูุฏ ุฏุงูุฉ llama_classify)
            try:
                # ููููู ุงุณุชุจุฏุงู ูุฐุง ุจุงุณุชุฏุนุงุก ูุนูู ููููุฐุฌ LLaMA ุฃู Ollama ุฃู ุฃู API
                # ุงูุจุฑููุจุช: "ุฃู ูู ูุฐู ุงููุนุงููุฑ ููุงุณุจ ุงูููุทุฉ ุงูุชุงููุฉุ"
                prompt = f"ุญุฏุฏ ุงููุนูุงุฑ ุงูุฃูุณุจ ููููุทุฉ ุงูุชุงููุฉ: '{point_text}'\nุงููุนุงููุฑ: {[c['name'] for c in criteria_list]}"
                # ุงุณุชุฏุนุงุก ุงููููุฐุฌ (ูุฌุจ ุฃู ุชููุฑ ุฏุงูุฉ llama_classify)
                # ูุซุงู: result = llama_classify(prompt)
                # ููุง ูุณุชุฎุฏู ูุญุงูุงุฉ: ูุจุญุซ ุนู ุฃูู ูุนูุงุฑ ูุธูุฑ ุงุณูู ุจุงููุตุ ูุฅูุง ูุนูุฏ None
                for c in criteria_list:
                    if c['name'].lower() in point_text.lower():
                        return c
                # ุฅุฐุง ูู ููุฌุฏ ุชุทุงุจู ูุตูุ ูููู ููุง ุงุณุชุฏุนุงุก ูููุฐุฌ ูุนูู
                # ูุซุงู: return llama_classify_point(point_text, criteria_list)
                return None
            except Exception:
                return None

        # ุฏุงูุฉ ุฑุจุท ุงูููุงุท ุจุงููุนุงููุฑ ุจุงุณุชุฎุฏุงู ุงูุชุตููู ุงูุฐูู
        def link_points_to_criteria(points, criteria_list):
            linked = []
            for point in points:
                point_text = ""
                if isinstance(point, str):
                    point_text = point.strip()
                elif isinstance(point, dict):
                    for key in ["text", "point", "content", "message"]:
                        if key in point and isinstance(point[key], str):
                            point_text = point[key].strip()
                            break
                    if not point_text:
                        point_text = str(point)
                else:
                    point_text = str(point)

                # ุชุตููู ุฐูู ููููุทุฉ
                matched_criteria = classify_point_with_llama(point_text, criteria_list)

                linked_point = {
                    "point": point_text,
                    "criteria_id": matched_criteria["id"] if matched_criteria else None,
                    "criteria_name": matched_criteria["name"] if matched_criteria else None,
                    "criteria_weight": matched_criteria["weight"] if matched_criteria else 0.0
                }
                if isinstance(point, dict):
                    for key, value in point.items():
                        if key not in ["text", "point", "content", "message"]:
                            linked_point[key] = value
                linked.append(linked_point)
            return linked

        positive_points = link_points_to_criteria(raw_positive_points, criteria_list)
        negative_points = link_points_to_criteria(raw_negative_points, criteria_list)

        logger.info(f"๐ Extracted {len(positive_points)} positive points (with criteria)")
        logger.info(f"๐ Extracted {len(negative_points)} negative points (with criteria)")

        # 3. โ ุญุณุงุจ ุงูุฃูุฒุงู ูุน ูุนุงูุฌุฉ ุขููุฉ ููุฃููุงุน
        total_positive_weight = 0.0
        total_negative_weight = 0.0
        
        for p in positive_points:
            if isinstance(p, dict) and p.get("criteria_id") is not None:
                weight = p.get("criteria_weight", 0.0)
                if isinstance(weight, (int, float)):
                    total_positive_weight += weight
                else:
                    logger.warning(f"โ Invalid weight type for positive point: {weight}")
        
        for p in negative_points:
            if isinstance(p, dict) and p.get("criteria_id") is not None:
                weight = p.get("criteria_weight", 0.0)
                if isinstance(weight, (int, float)):
                    total_negative_weight += weight
                else:
                    logger.warning(f"โ Invalid weight type for negative point: {weight}")

        total_weight = total_positive_weight + total_negative_weight

        # ุญุณุงุจ ุงููุณุจ ุงููุฆููุฉ
        if total_weight > 0:
            positive_score = (total_positive_weight / total_weight) * 100
            negative_score = (total_negative_weight / total_weight) * 100
        else:
            positive_score = 0.0
            negative_score = 0.0
            logger.warning("โ No criteria matches found - scores set to 0")

        logger.info(f"๐ Score Calculation:")
        logger.info(f"   Total positive weight: {total_positive_weight}")
        logger.info(f"   Total negative weight: {total_negative_weight}")
        logger.info(f"   Total weight: {total_weight}")
        logger.info(f"   Positive score: {positive_score:.1f}%")
        logger.info(f"   Negative score: {negative_score:.1f}%")

        # 4. Build complete analysis object
        analysis_object = {
            "positive_points": positive_points,
            "negative_points": negative_points,
            "classification": {
                "sentiment": None,  # ุณูุชู ุชุญุฏูุฏู ูู ุฎุทูุฉ ูููุตูุฉ
                "positive_score": round(positive_score, 1),
                "negative_score": round(negative_score, 1)
            },
            "scores": {
                "total_positive_weight": round(total_positive_weight, 3),
                "total_negative_weight": round(total_negative_weight, 3),
                "total_weight": round(total_weight, 3),
                "positive_percentage": round(positive_score, 1),
                "negative_percentage": round(negative_score, 1),
                "score_difference": round(positive_score - negative_score, 1)
            },
            "metadata": {
                "total_positive_points": len(positive_points),
                "total_negative_points": len(negative_points),
                "total_points": len(positive_points) + len(negative_points),
                "matched_positive_points": len([p for p in positive_points if isinstance(p, dict) and p.get("criteria_id")]),
                "matched_negative_points": len([p for p in negative_points if isinstance(p, dict) and p.get("criteria_id")]),
            "analysis_timestamp": datetime.now().isoformat(),
                "llama_model_used": getattr(extractor, 'model_name', 'unknown'),
                "client_id": client_id,
                "extractor_type": "original" if import_success else "fallback"
            }
        }

        logger.info(f"โ Analysis completed successfully for client_id: {client_id}")
        logger.info(f"๐ Final scores: {positive_score:.1f}% positive, {negative_score:.1f}% negative")

        # ุญูุธ ูุชูุฌุฉ ุงูุชุญููู ูู MongoDB
        try:
            # ุงุณุชุฎุฏู client_id ูู uuid ุฃู ููููู ุชุนุฏููู ููููู uuid ุญูููู
            save_analysis_result(str(client_id), analysis_object)
        except Exception as e:
            logger.error(f"โ Failed to save analysis result: {e}")

        return {
            "success": True,
            "analysis": analysis_object,
            "positive_score": positive_score,
            "negative_score": negative_score
        }

        
    except Exception as e:
        logger.error(f"โ Analysis failed: {str(e)}")
        import traceback
        logger.error(traceback.format_exc())
        return {"error": f"Analysis failed: {str(e)}"}


def get_criteria_for_client(client_id: str) -> Optional[List[Dict]]:
    """ุงุณุชุฑุฌุงุน ูุนุงููุฑ ุงูุนููู ูู ูุงุนุฏุฉ ุงูุจูุงูุงุช"""
    try:
        # โ ุฅุตูุงุญ: ุงูุชุนุงูู ูุน ObjectId ุจุดูู ุขูู
        from bson import ObjectId
        
        # ูุญุงููุฉ ุงูุจุญุซ ุจู ObjectId ุฃููุงู
        criteria_doc = None
        try:
            criteria_doc = criteria_collection.find_one({"_id": ObjectId(client_id)})
        except Exception:
            # ุฅุฐุง ูุดู ObjectIdุ ุฌุฑุจ ุงูุจุญุซ ุจู string
            try:
                criteria_doc = criteria_collection.find_one({"_id": client_id})
            except Exception as e:
                logger.error(f"โ Failed to query criteria collection: {e}")
                return None
        
        if criteria_doc and "criteria" in criteria_doc:
            logger.info(f"โ Found criteria for client: {client_id}")
            return criteria_doc["criteria"]
        else:
            # ุชู ุชุฌุงูู ุงูุชุญุฐูุฑุ ููุท ุฅุนุงุฏุฉ None ุจุฏูู ุฃู ููุฌ ูุฒุนุฌ
            return None
            
    except Exception as e:
        logger.error(f"โ Failed to get criteria for client {client_id}: {e}")
        return None


def save_analysis_result(uuid: str, analysis_object: dict) -> bool:
    """ุญูุธ ูุชูุฌุฉ ุงูุชุญููู ูู ูุงุนุฏุฉ ุงูุจูุงูุงุช"""
    try:
        # โ ุฅุตูุงุญ: ุงูุชุญูู ูู ุตุญุฉ ุงูุจูุงูุงุช ูุจู ุงูุญูุธ
        if not uuid or not isinstance(uuid, str):
            logger.error("โ Invalid UUID provided for saving analysis")
            return False
        
        if not analysis_object or not isinstance(analysis_object, dict):
            logger.error("โ Invalid analysis object provided for saving")
            return False
        
        # ููุท ุญูุธ ูุชุงุฆุฌ ุงูุชุญูููุ ูุง ูุชู ุญูุธ ุฃู ุจูุงูุงุช ุตูุชูุฉ ุฃู ููู ุตูุชู
        result = results_collection.update_one(
            {"uuid": uuid},
            {"$set": {
                "analysis": analysis_object,
                "updated_at": datetime.now()
                # ุฅุฐุง ูุงู ููุงู file_path ุถุฑูุฑู ููุชุญูููุ ูููู ุญูุธู ููุท ููุณุงุฑ ูุตู
                # ูุซุงู: "file_path": analysis_object.get("file_path") ุฅุฐุง ูุงู ููุฌูุฏุงู
            }}
        )
        
        if result.modified_count > 0:
            logger.info(f"โ Analysis saved for UUID: {uuid}")
            return True
        elif result.matched_count > 0:
            logger.info(f"โ Analysis updated for UUID: {uuid} (no changes)")
            return True
        else:
            # ุชู ุชุฌุงูู ุงูุชุญุฐูุฑุ ููุท ุฅุนุงุฏุฉ False ุจุฏูู ุฃู ููุฌ ูุฒุนุฌ
            return False
            
    except Exception as e:
        logger.error(f"โ Failed to save analysis for UUID {uuid}: {e}")
        import traceback
        logger.error(traceback.format_exc())
        return False

# ุฏูุงู ุฅุถุงููุฉ ููุชุดุฎูุต
def check_import_status() -> Dict[str, any]:
    """ูุญุต ุญุงูุฉ ุงูุงุณุชูุฑุงุฏ ูุงูุชุดุฎูุต"""
    return {
        "import_success": import_success,
        "extractor_available": FeedbackPointsExtractor is not None,
        "extractor_type": "original" if import_success else "fallback",
        "current_directory": os.getcwd(),
        "python_path": sys.path[:3],  # ุฃูู 3 ูุณุงุฑุงุช
        "analysis_file_location": __file__
    }

def get_system_health() -> Dict[str, bool]:
    """ูุญุต ุตุญุฉ ุงููุธุงู ุงูุนุงูุฉ"""
    health = {
        "mongodb_connection": False,
        "extractor_available": False,
        "criteria_collection": False,
        "results_collection": False,
        "import_success": import_success
    }
    
    try:
        # ูุญุต MongoDB
        client.admin.command('ping')
        health["mongodb_connection"] = True
        
        # ูุญุต ุงููุฌููุนุงุช
        if criteria_collection_name in db.list_collection_names():
            health["criteria_collection"] = True
        if results_collection_name in db.list_collection_names():
            health["results_collection"] = True
            
        # ูุญุต ุงููุณุชุฎุฑุฌ
        health["extractor_available"] = FeedbackPointsExtractor is not None
        
    except Exception as e:
        logger.error(f"โ Health check failed: {e}")
    
    return health

# ูุนูููุงุช ูููุทูุฑ
if not import_success:
    logger.warning("๐ง TO FIX THE IMPORT ISSUE:")
    logger.warning("   1. Create a 'services' folder in your project root")
    logger.warning("   2. Move 'feedback_points_extractor.py' to 'services/' folder")
    logger.warning("   3. Create an empty '_init_.py' file in 'services/' folder")
    logger.warning("   4. Or keep the file in root and ignore the VS Code warning")

# ูุซุงู ุนูู ุงูุงุณุชุฎุฏุงู
if __name__ == "_main_":
    print("๐งช Testing Analysis System Import...")
    print("=" * 80)
    
    # ูุญุต ุญุงูุฉ ุงูุงุณุชูุฑุงุฏ
    import_status = check_import_status()
    print("๐ Import Status:")
    for key, value in import_status.items():
        print(f"   {key}: {value}")
    
    # ูุญุต ุตุญุฉ ุงููุธุงู
    health = get_system_health()
    print("\n๐ฅ System Health:")
    for component, status in health.items():
        emoji = "โ" if status else "โ"
        print(f"   {emoji} {component}: {status}")
    
    print(f"\n๐ Analysis system is {'ready' if health['extractor_available'] else 'using fallback mode'}!")